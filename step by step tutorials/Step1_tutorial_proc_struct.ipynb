{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "156b4fed-8da6-4398-985f-3e550c4f98dc",
   "metadata": {},
   "source": [
    "# Structural Processing with Micapipe begins!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a9d47d-4e03-4258-8cc9-7d5de536a260",
   "metadata": {},
   "source": [
    "## This section explains how to run the proc_structural workflow, how the SLURM submission works, how to interpret each part of the script, and where to find your outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc583fd-b060-4844-9d4c-f965420c59f2",
   "metadata": {},
   "source": [
    "*Micapipe’s structural pipeline provides a comprehensive and standardized framework for transforming raw T1-weighted MRI data into high-quality cortical surfaces, anatomical segmentations, and morphometric features. This processing stream integrates established neuroimaging tools with optimized workflows to ensure reproducibility and reliability across participants and studies.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140c5da-c1d8-4f83-8c54-6e44121a4cae",
   "metadata": {},
   "source": [
    "### Now lets break down example command for running proc_structural on a SLURM: all the ingredients that we need are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8045198-8106-463e-9c4f-f69dfa95299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#SBATCH -c 10\n",
    "#SBATCH --mem 15G\n",
    "#SBATCH --time 5:00:00\n",
    "#SBATCH --job-name struct\n",
    "#SBATCH --partition=standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588349f-cc5c-4478-a52f-ee88f6f4963d",
   "metadata": {},
   "source": [
    "\n",
    "   1. The first line requests 10 CPU cores for your job (-c10). It tells the cluster that your program should run using 10 parallel threads.\n",
    "   2. Next is the Memory (-mem 15G). This requests 15 GB of RAM. SLURM will only place your job on a compute node that has at least this much free memory. If your job uses more memory than you requested, it may be killed, so this value is important to set correctly.\n",
    "   3. Runtime Limit (-time 5:00:00). This sets the maximum allowed runtime for the job to 5 hours. If the job exceeds this limit, the scheduler automatically cancels it.Useful for preventing jobs from running indefinitely.\n",
    "   4. Job Name (-job-name struct). This assigns a custom name to your job—for example, “struct”. It helps you easily identify your job when checking the queue or your job history.\n",
    "   5. Partition (-partition=standard) This selects the cluster partition (queue) where the job should run. Clusters usually offer partitions like “standard”, “high-memory”, “GPU”, etc. The partition controls priority, hardware type, and resource limits. The higher priority, the faster cluster starts the submitted job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f8ecf6-e269-454f-acc8-cdeb17970a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cores\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57517b6b-0d93-45e5-8a1d-69ef4c434ab9",
   "metadata": {},
   "source": [
    "This export command ensures that your software uses the same number of threads as the CPU cores you requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012adb5-b4ca-447d-a389-030b9e5027ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tmp\n",
    "job_tmp_dir=$TMPDIR/$SLURM_JOB_ID\n",
    "mkdir $job_tmp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500553a-94b1-4ab1-93a1-d9795b21d2fb",
   "metadata": {},
   "source": [
    "The Temporary Working Directory and The SLURM. *(if you are not familiar with the SLURM you can find information in the helpbook document mention in the README.md file of this repo)* The tmp line defines the temporary working directory on the compute node. This is required on SLURM because each compute node has its own local space. Using local scratch improves speed and prevents network storage overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b6d315-4cf2-4c40-b983-aace6aaa2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "sub=$1\n",
    "ses=$2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002977fc-1f3f-4768-b10a-7d5768cfe3f1",
   "metadata": {},
   "source": [
    "Parameters define the **subject** and **session** labels in your BIDS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8eb71-e3fd-43da-9660-a2d50c58eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "micapipe_img=/data/p_SoftwareServiceLinux_micapipe/0.2.3/singularity/\n",
    "bids=/data/your/BIDS\n",
    "out=/data/your/BIDS/derivatives\n",
    "fs_lic=/data/your/resources/license.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba81ecec-d0a6-4e1e-89b1-b7caedb75933",
   "metadata": {},
   "source": [
    "micapipe_img = This is the Micapipe Singularity/Apptainer image, e.g.: micapipe_v0.2.3.sif\n",
    "\n",
    "*Why you need it*: Contains all required software (FreeSurfer, FSL, ANTs, MRtrix3) Guarantees reproducibility. Ensures the correct Micapipe version. How to get it: Download from the official release page. Or build it locally using the Micapipe recipe. Potential error: If the image is missing or not correctly bound, the job will fail before structural processing begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d3917-6382-4cd7-892d-f0dfc27ea9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "singularity run --cleanenv --writable-tmpfs --containall \\\n",
    "    -B ${bids}:/bids \\\n",
    "\t-B ${out}:/out \\\n",
    "\t-B ${job_tmp_dir}:/tmp \\\n",
    "\t-B ${fs_lic}:/opt/licence.txt \\\n",
    "\t${micapipe_img} \\\n",
    "\t-bids /bids -out /out -fs_licence /opt/licence.txt -threads ${OMP_NUM_THREADS} -sub ${sub} -ses ${ses} \\\n",
    "    -proc_structural\n",
    "\n",
    "# Clean up the temporary data at the end of the job.\n",
    "rm -fr $job_tmp_dir\n",
    "\n",
    "check_ComputeClusterSlurm_memory-usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa355c-af8f-428a-aba8-4ace3c7c379c",
   "metadata": {},
   "source": [
    "### Notice the last line -proc_structural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0acba-e06a-4d9b-989f-669d5f9597c0",
   "metadata": {},
   "source": [
    "It is crucial to have this line of command in order to run the structural processing with Micapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d868ba-8e9a-4e50-94ac-87b55b8770de",
   "metadata": {},
   "source": [
    "Now we have saved the command line above in the file named: *proc_struct.sh*; When constructing the wrapper for this script notice where you need to adpt to your path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324d75e-66cb-480b-8e77-f3bdc1b562c1",
   "metadata": {},
   "source": [
    "# This is a wrapper that will call the command line above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0782aa2-1c94-4d16-b476-6c3f223bd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# create directory to save log files\n",
    "logs_dir=\"/data/your/path/to/logs\"\n",
    "\n",
    "#run job\n",
    "sub=\"0001\"\n",
    "ses=\"01\"\n",
    "\n",
    "sbatch --error \"${logs_dir}/${sub}_${ses}\".err \\\n",
    "    --output \"${logs_dir}/${sub}_${ses}\".out \\\n",
    "    /data/your/scripts/proc_struct.sh  \"${sub}\" \"${ses}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9404ef0-1273-406a-a69a-13edca7d4c63",
   "metadata": {},
   "source": [
    "Adapt the last line of code to match the path to your script and its name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8bf79e-d185-4b73-8338-210243ec521c",
   "metadata": {},
   "source": [
    "## In order to run the script we have constructed above (you can see the script used for the Spacetop Dataset preprocessing in the scripts folder of the repo) What we do from now is that we send our wrapper script to a submission node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c8a9c8-70c0-4478-97dd-c7ff21856dc6",
   "metadata": {},
   "source": [
    "Please move on to the next Step 2 tutorial SLURM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1047f0-6700-48dc-8731-286b93bb279f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
